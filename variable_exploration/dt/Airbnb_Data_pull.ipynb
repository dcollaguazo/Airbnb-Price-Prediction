{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This imports the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import kaggle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# This is for pulling from Google Drive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "\n",
    "# For some file navigation to download the files to the correct spots\n",
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "# On windows, if using the pip install method, you must: \n",
    "#    manually download GDAL and Fiona packages from https://www.lfd.uci.edu/~gohlke/pythonlibs/\n",
    "#    go to directory where they are downloaded, pip install <filename>.whl\n",
    "#    after that, 'pip install geopandas' works normally.\n",
    "import geopandas as gpd\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This downloads the kaggle data set (Not used as far as I know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "#Kaggle data api\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "#download the Kaggle Dataset\n",
    "kaggle.api.dataset_download_files('dgomonov/new-york-city-airbnb-open-data', path='C:\\\\Users\\\\darie\\\\Desktop\\\\Python Practice\\\\Airbnb-Price-Prediction\\\\data\\\\new-york-city-airbnb-open-data', unzip=True)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This goes to the Airbnb website, and pulls the html from the page. #\n",
    "**From there it finds the new-york-city table, and gets the urls for the first 7 csvs, anything past that is historical data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the latest csv file urls for the data sets\n",
    "\n",
    "''' COMMENTED OUT TO AVOID ACCIDENTALLY RUNNING IT; SITE GOT OVERLOADED BY DOWNLOADS; SO ONLY DO THIS IF NECESSARY\n",
    "\n",
    "# To do this, I go to the website that lists all the downloads ...\n",
    "\n",
    "airbnb_data_url = 'http://insideairbnb.com/get-the-data.html'\n",
    "soup = BeautifulSoup(requests.get(airbnb_data_url).text)\n",
    "\n",
    "# Find the table with the new york city data sets ...\n",
    "new_york_table = soup.find_all('table',{'class':'new-york-city'})\n",
    "\n",
    "# Get the first 7 rows in the table (excluding the header row) ...\n",
    "csv_files = new_york_table[0].find_all('tr')[1:8]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once we have the csv paths, we can import them using pandas or geopandas for the geojson file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csvs into their own variables depending on the path\n",
    "# Note: the gz files are zipped, so we need to unzip them when we read them in.\n",
    "'''\n",
    "\n",
    "for x in csv_files:\n",
    "    href = x.find('a')['href']\n",
    "    print(href)\n",
    "    \n",
    "    if 'data/listings.csv.gz' in href:\n",
    "        airbnb_listings_data = pd.read_csv(href, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "        \n",
    "    elif 'data/calendar.csv.gz' in href:\n",
    "        airbnb_calendar_data = pd.read_csv(href, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "        \n",
    "    elif 'data/reviews.csv.gz' in href:\n",
    "        airbnb_reviews_data = pd.read_csv(href, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "        \n",
    "    elif 'visualisations/listings.csv' in href:\n",
    "        #airbnb_listings_visual = pd.read_csv(href)\n",
    "        \n",
    "    elif 'visualisations/reviews.csv' in href:\n",
    "        #airbnb_reviews_visual = pd.read_csv(href)\n",
    "        \n",
    "    elif 'visualisations/neighbourhoods.csv' in href:\n",
    "        airbnb_neighbourhoods_visual = pd.read_csv(href)\n",
    "        \n",
    "    elif 'visualisations/neighbourhoods.geojson' in href:\n",
    "        airbnb_neighbourhoods_visual_json = gpd.read_file(href)\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull files from Google Drive #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created this to find the main Airbnb folder\n",
    "def GoToParentFolder(folder_name):\n",
    "    path = Path(os.getcwd())\n",
    "    path_string = str(path)\n",
    "\n",
    "    while path_string[-len(folder_name):] != folder_name:\n",
    "        path = Path(path.parent)\n",
    "        path_string = str(path)\n",
    "        print(path_string)\n",
    "        \n",
    "    return(str(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory to the data folder\n",
    "airbnb_main_directory = GoToParentFolder('Airbnb-Price-Prediction')\n",
    "\n",
    "data_folder = os.path.join(airbnb_main_directory,'data','Google Drive Docs')\n",
    "\n",
    "if os.path.exists(data_folder) == False:\n",
    "    os.mkdir(data_folder)\n",
    "    missing_folder = True\n",
    "\n",
    "else:\n",
    "    missing_folder = False\n",
    "    \n",
    "os.chdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main data files\n",
    "listings_path = os.path.join(data_folder, 'listings.csv.gz')\n",
    "reviews_path = os.path.join(data_folder, 'reviews.csv.gz')\n",
    "calendar_path = os.path.join(data_folder, 'calendar.csv.gz')\n",
    "\n",
    "# supplimentary files\n",
    "neighbourhoods_geo_path = os.path.join(data_folder, 'neighbourhoods.geojson')\n",
    "neighbourhoods_csv_path = os.path.join(data_folder, 'neighbourhoods.csv')\n",
    "federal_holidays_path = os.path.join(data_folder, 'federal-holidays-usa-19662020.zip')\n",
    "\n",
    "# Checks if files are present or not\n",
    "if (os.path.exists(listings_path) == False or\n",
    "    os.path.exists(reviews_path) == False or\n",
    "    os.path.exists(calendar_path) == False or\n",
    "    os.path.exists(neighbourhoods_geo_path) == False or \n",
    "    os.path.exists(neighbourhoods_csv_path) == False or\n",
    "    os.path.exists(federal_holidays_path) == False or\n",
    "    missing_folder == True):\n",
    "    need_to_pull_data = True\n",
    "\n",
    "else:\n",
    "    need_to_pull_data = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if need_to_pull_data == True:\n",
    "    print(\"One or more missing files don't appear to be downloaded. The next few cells will download them...\")\n",
    "    drive_download = \"Y\"\n",
    "    \n",
    "elif need_to_pull_data == False:\n",
    "    drive_download = input(\"Would you like to download the data files from Google Drive? Y/N\").upper()\n",
    "    \n",
    "    if drive_download == \"Y\":\n",
    "        override_download = input(\"Where files already exist on your machine, would you like to overwrite them? Y/N\").upper()\n",
    "    else:\n",
    "        print(\"Files will NOT be downloaded...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drive_download == \"Y\":\n",
    "    # Do google authorization to access the google drive.\n",
    "    # This requires setting up an Google OAuth client IDs key for google drive (https://console.developers.google.com/)\n",
    "    #     then downloading and adding the client_secrets.json to the Google Drive Docs folder created in the above cell\n",
    "\n",
    "    # 1. We need to have authorization for the drive because its no Georgetown's Google Drive\n",
    "    gauth = GoogleAuth()\n",
    "    gauth.LocalWebserverAuth()\n",
    "    \n",
    "    try:\n",
    "        drive = GoogleDrive(gauth)\n",
    "    except:\n",
    "        print('You must download')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if drive_download == \"Y\":\n",
    "    # 2. Auto-iterate using the query syntax\n",
    "    #    https://developers.google.com/drive/v2/web/search-parameters\n",
    "    file_list = drive.ListFile(\n",
    "        {'q': \"'1wKkNN17AUxKU0dCYxmu_iUBe89QuUOQ4' in parents\"}).GetList()  #use your own folder ID here\n",
    "\n",
    "    for f in file_list:\n",
    "        # 3. Create & download by id.\n",
    "\n",
    "        print('\\n title: %s, id: %s' % (f['title'], f['id']))\n",
    "        fname = f['title']\n",
    "\n",
    "        if os.path.exists(os.path.join(data_folder,f['title'])) == False or override_download == \"Y\":\n",
    "            try:\n",
    "                print(\"downloading '{}'...\".format(fname))\n",
    "                f_ = drive.CreateFile({'id': f['id']})\n",
    "                f_.GetContentFile(fname)\n",
    "\n",
    "            except:\n",
    "                print(color.BOLD + color.RED +\"** '{}' Failed to download\".format(fname)  + color.END)\n",
    "\n",
    "        else:\n",
    "            print(\" ** '{}' already exists. Nothing was done.\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Load CSVs into pandas data frames\n",
    "\n",
    "# Main data files\n",
    "listings_data = pd.read_csv(listings_path, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "reviews_data = pd.read_csv(reviews_path, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "calendar_data = pd.read_csv(calendar_path, compression='gzip', header=0, sep=',', quotechar='\"', error_bad_lines=False)\n",
    "\n",
    "# supplimentary files\n",
    "neighbourhoods_geo_data = gpd.read_file(neighbourhoods_geo_path)\n",
    "neighbourhoods_csv_data = pd.read_csv(neighbourhoods_csv_path)\n",
    "\n",
    "zf = zipfile.ZipFile(federal_holidays_path) \n",
    "federal_holidays_data = pd.read_csv(zf.open('usholidays.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just checking that they are all imported correctly\n",
    "\n",
    "'''\n",
    "\n",
    "print(listings_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "print(reviews_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "print(calendar_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "# supplimentary files\n",
    "print(neighbourhoods_geo_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "print(neighbourhoods_csv_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "print(federal_holidays_data.head(10))\n",
    "print('\\n+++++++++++++++++++++++++++++++++++++++++++++\\n')\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}