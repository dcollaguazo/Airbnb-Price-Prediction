{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/danielacollaguazo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "/Users/danielacollaguazo/anaconda/envs/GTWorkshops/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run in python console\n",
    "import nltk; nltk.download('stopwords')\n",
    "import spacy\n",
    "\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "\n",
    "import shutil\n",
    "import glob\n",
    "from tika import parser\n",
    "\n",
    "from yellowbrick.features import rank2d\n",
    "from yellowbrick.classifier import confusion_matrix\n",
    "from yellowbrick.classifier import classification_report\n",
    "from yellowbrick.regressor import prediction_error, ResidualsPlot\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../data/new-york-city-airbnb-open-data/'\n",
    "listings_csv = os.path.join(path,'listings.csv')\n",
    "\n",
    "listings_df =  pd.read_csv(listings_csv,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in listings_df.columns:\n",
    "#     print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((listings_df.summary.isna().sum())/listings_df.shape[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for text in the data\n",
    "listings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lang(x):\n",
    "    lang=''\n",
    "    txt_len=len(x)\n",
    "    if txt_len>50:\n",
    "        try:\n",
    "            lang=detect(x)\n",
    "        except Exception as e:\n",
    "            lang=''\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df['content'] = listings_df['name'] + listings_df['description']\n",
    "listings_df.dropna(subset=['content'], how='any', axis=0, inplace=True)\n",
    "listings_df['content_lang'] = listings_df.content.apply(lambda x: predict_lang(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting only text in English\n",
    "listings_df=listings_df[listings_df.content_lang=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49022, 108)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listings_df.to_csv(os.path.join(path,'content_en.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_list_content(df):\n",
    "#     df['content'] = df['name'] + df['summary']\n",
    "#     df['content'] = df['content'].replace(np.nan, '', regex=True)\n",
    "    \n",
    "    # Convert to list\n",
    "    data = df['content'].values.tolist()\n",
    "\n",
    "    # Remove Emails\n",
    "    data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_texts = generate_list_content(listings_df)\n",
    "# listings_df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49022"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize words and clean up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are tokenizing each document.\n",
    "def content_to_words(lst_texts):\n",
    "    for text in lst_texts:\n",
    "        yield(gensim.utils.simple_preprocess(str(text), deacc=True))\n",
    "        \n",
    "# data_words is a list where each element is the tokenized document\n",
    "tokenized_content = list(content_to_words(lst_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create bigram and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(tokenized_content, min_count=10, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[tokenized_content], threshold=100)  \n",
    "\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(tokenized_content):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in tokenized_content]\n",
    "\n",
    "def make_bigrams(tokenized_content):\n",
    "    return [bigram_mod[doc] for doc in tokenized_content]\n",
    "\n",
    "def make_trigrams(tokenized_content):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in tokenized_content]\n",
    "\n",
    "def lemmatization(tokenized_content, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in tokenized_content:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stop Words\n",
    "tokenized_content_nostops = remove_stopwords(tokenized_content)\n",
    "\n",
    "# Form Bigrams\n",
    "tokenized_content_bigrams = make_bigrams(tokenized_content_nostops)\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "tokenized_content_lemmatized = lemmatization(tokenized_content_bigrams, \n",
    "                                             allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary:\n",
    "# Mapping from word IDs to words. \n",
    "# It is used to determine the vocabulary size, as well as for debugging and topic printing.\n",
    "id2word = corpora.Dictionary(tokenized_content_lemmatized)\n",
    "# print(len(id2word)) # corpus has 14118 unique tokens\n",
    "\n",
    "# Term Document Frequency\n",
    "# Convert document (a list of words) into the bag-of-words format = list of (token_id, token_count) 2-tuples.\n",
    "# Word with their corresponding id\n",
    "corpus = [id2word.doc2bow(text) for text in tokenized_content_lemmatized]\n",
    "\n",
    "# View\n",
    "# print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build list of topic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_topics(num_topics):\n",
    "    list_models=[]\n",
    "    for n in num_topics:\n",
    "        topic_name = 'lda_model_' + str(n)\n",
    "        topic_name = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, \n",
    "                                                     num_topics=n, random_state=100, \n",
    "                                                     update_every=1, chunksize=100, \n",
    "                                                     passes=10, alpha='auto', \n",
    "                                                     per_word_topics=True)\n",
    "        list_models.append(topic_name)\n",
    "    return list_models\n",
    "\n",
    "num_topics = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "models = build_topics(num_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Model Perplexity and Coherence Score for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_perplexity_coherence(models):\n",
    "    list_perplexity = []\n",
    "    list_coherence = []\n",
    "    \n",
    "    for model in models:\n",
    "        list_perplexity.append(model.log_perplexity(corpus))\n",
    "        coherence_model_lda = CoherenceModel(model=model, texts=tokenized_content_lemmatized, \n",
    "                                             dictionary=id2word, coherence='c_v')\n",
    "        list_coherence.append(coherence_model_lda.get_coherence())\n",
    "    return list_perplexity, list_coherence\n",
    "\n",
    "x = calc_perplexity_coherence(models)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(list(x)).transpose()\n",
    "df_metrics.columns = ['Perplexity','Coherence']\n",
    "df_metrics['Number of topics'] = num_topics\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphic of number of Topics and Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity needs to be as low as possible \n",
    "plt.plot( 'Number of topics', 'Perplexity', data=df_metrics, color='skyblue')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Perplexity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphic of number of Topics and Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perplexity needs to be as low as possible \n",
    "plt.plot( 'Number of topics', 'Coherence', data=df_metrics, color='orange')\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most salient topic per file using results of Model of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def format_topics_sentences(ldamodel=None, corpus=corpus, texts=lst_texts):\n",
    "#     # Init output\n",
    "#     sent_topics_df = pd.DataFrame()\n",
    "\n",
    "#     # Get main topic in each document\n",
    "#     for i, row_list in enumerate(ldamodel[corpus]):\n",
    "#         row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "#         print(row)\n",
    "#         row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "#         # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "#         for j, (topic_num, prop_topic) in enumerate(row):\n",
    "#             if j == 0:  # => dominant topic\n",
    "#                 wp = ldamodel.show_topic(topic_num)\n",
    "#                 topic_keywords = \", \".join([word for word, prop in wp])\n",
    "#                 sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num) + 1, \n",
    "#                                                                   round(prop_topic,4), \n",
    "#                                                                   topic_keywords]), ignore_index=True)\n",
    "#             else:\n",
    "#                 break\n",
    "#     sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "#     # Add original text to the end of the output\n",
    "# #     contents = pd.Series(texts)\n",
    "#     sent_topics_df = pd.concat([listings_df,sent_topics_df], axis=1, sort=False)\n",
    "#     return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame with scores of all topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=lst_texts):\n",
    "    # Init output\n",
    "    sent_topics_df = list()\n",
    "    listings_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        sent_topics_df.append(row)\n",
    "        \n",
    "    sent_topics_df = pd.DataFrame(sent_topics_df)\n",
    "    sent_topics_df.columns = ['Dominant_Topic_1', 'Dominant_Topic_2', 'Dominant_Topic_3']\n",
    "    sent_topics_df = pd.concat([listings_df['id'],sent_topics_df], axis=1, sort=False)\n",
    "    \n",
    "#     sent_topics_df.rename(columns={\"id\": \"listing_id\"},inplace=True)\n",
    "    \n",
    "#     sent_topics_df.set_index('listing_id',inplace=True)\n",
    "    \n",
    "    df_n_cols = sent_topics_df.shape[1]\n",
    "    \n",
    "    return sent_topics_df, df_n_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df, df_n_cols = format_topics_sentences(ldamodel=models[1], corpus=corpus, texts=lst_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,df_n_cols):\n",
    "    top_col = 'topic' + str(i)\n",
    "    score_col = 'score_dom_topic_' + str(i)\n",
    "    \n",
    "    sent_topics_df[top_col] = pd.DataFrame(sent_topics_df.iloc[:,i].tolist(), index=sent_topics_df.index)[0]\n",
    "    sent_topics_df[score_col] = pd.DataFrame(sent_topics_df.iloc[:,i].tolist(), index=sent_topics_df.index)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_drop = ['Dominant_Topic_1', 'Dominant_Topic_2','Dominant_Topic_3']\n",
    "sent_topics_df.drop(columns=cols_2_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df.to_csv(os.path.join(path,'topics_with_scores.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df = pd.read_csv(os.path.join(path,'topics_with_scores.csv'),index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_main_topic_df = sent_topics_df[['id','topic1','score_dom_topic_1']]\n",
    "sent_topics_df.rename(columns={\"topic1\": \"winner_topic\",\n",
    "                                   \"score_dom_topic_1\":\"winner_topic_score\",\n",
    "                                  \"topic2\": \"second_place_topic\",\n",
    "                                   \"score_dom_topic_2\":\"second_topic_score\",\n",
    "                                  \"topic3\": \"third_place_topic\",\n",
    "                                   \"score_dom_topic_3\":\"third_topic_score\"},inplace=True)\n",
    "\n",
    "# sent_main_topic_df.to_csv(os.path.join(path, 'winner_topic.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df = sent_topics_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(models[1], corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating the Dominant Topics with the rest of the Features for Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cols_df = pd.read_csv('../data/new-york-city-airbnb-open-data/model_columns_listings.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.merge(left=model_cols_df, right=sent_topics_df, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df_model.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list()\n",
    "for col in df_model.columns:\n",
    "    features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df_model.groupby('winner_topic')['winner_topic'].size()\n",
    "print(df)\n",
    "df.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "df_3 = df_model.loc[:,['review_scores_rating','winner_topic', 'winner_topic_score', 'second_place_topic',\n",
    "                       'second_topic_score', 'third_place_topic', 'third_topic_score','price']]\n",
    "\n",
    "sns.pairplot(df_3,height=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split train - test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_model.iloc[:, 1:]\n",
    "X = X.loc[:, X.columns != 'price']\n",
    "y = df_model.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "regressors = {\n",
    "#     \"support vector machine\": SVR(),\n",
    "#     \"multilayer perceptron\": MLPRegressor(),\n",
    "#     \"nearest neighbors\": KNeighborsRegressor(),\n",
    "#     \"bayesian ridge\": BayesianRidge(),\n",
    "#     \"linear regression\": LinearRegression(),\n",
    "    \"random forest\": RandomForestRegressor(),\n",
    "}\n",
    "\n",
    "for _, regressor in regressors.items():\n",
    "    visualizer = ResidualsPlot(regressor)\n",
    "    visualizer.fit(X_train, y_train)\n",
    "    visualizer.score(X_test, y_test)\n",
    "    visualizer.show()\n",
    "    \n",
    "    viz = FeatureImportances(regressor, labels=features, size=(1080, 1080))\n",
    "\n",
    "    viz.fit(X_train, y_train)\n",
    "    # Note: the FeatureImportances visualizer is a model visualizer,\n",
    "    # not a feature visualizer, so it doesn't have a transform method!\n",
    "    viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_features =['room_type_Entire home/apt',\n",
    "# 'bathrooms',\n",
    "# 'neighbourhood_group_cleansed_Manhattan',\n",
    "# 'bedrooms',\n",
    "# 'host_since',\n",
    "# 'reviews_per_month',\n",
    "# 'accommodates',\n",
    "# 'third_topic_score',\n",
    "# 'last_review_days_ago',\n",
    "# 'amenities_count',\n",
    "# 'second_topic+score',\n",
    "# 'number_of_reviews',\n",
    "# 'review_scores_rating',\n",
    "# 'guest_included',\n",
    "# 'number_of_reviews_ltm',\n",
    "# 'review_scores_location',\n",
    "# 'beds',\n",
    "# 'apt_yes_no',\n",
    "# 'review_scores_value',\n",
    "# 'review_scores_cleanliness']\n",
    "\n",
    "top_features =['bathrooms','bedrooms','reviews_per_month','price','third_topic_score']\n",
    "\n",
    "df_4 = df_model.loc[:,top_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_4,height=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
